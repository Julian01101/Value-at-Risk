EWMA_mean <- rep(0,numb_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:(back_obs)])
# Recursive definition for EWMA
for (i in 1:(numb_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + Returns[(back_obs+i)]*0.03
}
# Sigma2
# Pre allocate space and initialize first component
sigma2 <- rep(0, numb_pred)
sigma2[1] <- var(PortLoss[1:(1+back_obs)])
# Recursive equation for sigma
for(i in 1:(numb_pred-1)){
sigma2[i+1] <- 0.97*sigma2[i] + 0.03*(Returns[(i+back_obs)]-EWMA_mean[i])^2
}
plot(EWMA_mean, main = "EWMA means over time")
plot(sigma2, main = "Volatility over time")
Var <- rep(0, numb_pred)
Var <- -(exp(EWMA_mean[(2:numb_pred)]+sqrt(sigma2[(2:numb_pred)])*qnorm(0.95))-1)
Violations <- PortLoss[(back_obs):(numb_obs-2)] < Var
sum(Violations)
plot(EWMA_mean, main = "EWMA means over time")
# HW2Q5Pt1
# This file calculates the 95% VaR using a GARCH(1,1) method with EWMA means of the SP 500.
# We use a 4 year rolling window horizon to calibrate the parameters.
# We then back test the theoretical VaR against the next prediction of the next day to see if it falls outside the 95%
# We are looking the number of times the observed data exceeds the theoretical formulation.
# We expect the number of violations to be within the confidence interval in file ConfInt.R
# Let's get started....
# Set up the working directory and get the files needed
library(tseries)
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
# check the ordering of the date to make sure we are going forwards through time
back_obs <- 999  # Number of periods we go back to estimate the GARCH model
num_pred <- dim(SPData)[1]-back_obs
# Pre allocate space
coefs <- data.frame(matrix(0,nrow = num_pred, ncol = 3))
names(coefs)[1:3] <- c("a0", "a1", "b1")
for (i in 1:num_pred){ # Rolling window for the GARCH estimates
# Hypotetical Loss Operator - rolling window for 999 periods
PortLoss <- SPData[i:(i+back_obs),5]
# Fit Garch to portfolio losses (Trace = suppresses output to console, default is GARCH 1,1)
fit1 <- garch(PortLoss, trace = FALSE)
# Save coefficients of Garch models
coefs[i,1:3] <- fit1$coef
}
index <- seq(from = 1, to =dim(coefs)[1], by =1)
plot(index,coefs[,2])
# EWMA means
EWMA_mean <- rep(0,num_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:back_obs])
# Recursive definition for EWMA
for (i in 1:(num_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + SPData[(back_obs+i),5]*0.03
}
# Sigma 2 Initilization
sigma2 <- rep(0, num_pred)
sigma2[1] <- var(PortLoss[1:back_obs])
# Simga2 recursive definition using the coefficients from the rolling GARCH
for(i in 1:(num_pred-1)){
sigma2[(i+1)] <- coefs[i,1] + coefs[i,2]*(SPData[(back_obs+i),5]-EWMA_mean[i])^2+coefs[i,3]*sigma2[i]
}
plot(sigma2, main = " GARCH Volatility over time")
# HW2Q5Pt3
# This file computes the 95% VaR using variance/ covariance method with EWMA means and EMWA volatility
# We then back test the theoretical VaR against the next prediction of the next day to see if it falls outside the 95%
# We are looking the number of times the observed data exceeds the theoretical formulation.
# We expect the number of violations to be within the confidence interval in file ConfInt.R
# Let's get started
# Set up the working directory and get the files needed
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
# Some intial parameters
numb_obs <- dim(SPData)[1]
back_obs <- 999
numb_pred <- numb_obs- back_obs
Returns <- SPData$Log.Return
PortLoss <- SPData$Hypothetical.Portfolio.Loss
# EWMA means
EWMA_mean <- rep(0,numb_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:(back_obs)])
# Recursive definition for EWMA
for (i in 1:(numb_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + Returns[(back_obs+i)]*0.03
}
# Sigma2
# Pre allocate space and initialize first component
sigma2 <- rep(0, numb_pred)
sigma2[1] <- var(PortLoss[1:(1+back_obs)])
# Recursive equation for sigma
for(i in 1:(numb_pred-1)){
sigma2[i+1] <- 0.97*sigma2[i] + 0.03*(Returns[(i+back_obs)]-EWMA_mean[i])^2
}
# Take a peak at means and volatility
plot(EWMA_mean, main = "EWMA means over time")
plot(sigma2, main = "EWMA Volatility over time")
# Calculate VaR and check for violations
Var <- rep(0, numb_pred)
Var <- -(exp(EWMA_mean[(2:numb_pred)]+sqrt(sigma2[(2:numb_pred)])*qnorm(0.95))-1)
Violations <- PortLoss[(back_obs):(numb_obs-2)] < Var
# This file computes the 95% VaR using variance/ covariance method with EWMA means and EMWA volatility
# We then back test the theoretical VaR against the next prediction of the next day to see if it falls outside the 95%
# We are looking the number of times the observed data exceeds the theoretical formulation.
# We expect the number of violations to be within the confidence interval in file ConfInt.R
# Let's get started
# Set up the working directory and get the files needed
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
# Some intial parameters
numb_obs <- dim(SPData)[1]
back_obs <- 999
numb_pred <- numb_obs- back_obs
Returns <- SPData$Log.Return
PortLoss <- SPData$Hypothetical.Portfolio.Loss
# EWMA means
EWMA_mean <- rep(0,numb_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:(back_obs)])
# Recursive definition for EWMA
for (i in 1:(numb_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + Returns[(back_obs+i)]*0.03
}
# Sigma2
# Pre allocate space and initialize first component
sigma2 <- rep(0, numb_pred)
sigma2[1] <- var(PortLoss[1:(1+back_obs)])
# Recursive equation for sigma
for(i in 1:(numb_pred-1)){
sigma2[i+1] <- 0.97*sigma2[i] + 0.03*(Returns[(i+back_obs)]-EWMA_mean[i])^2
}
# Take a peak at means and volatility
plot(EWMA_mean, main = "EWMA means over time")
plot(sigma2, main = "EWMA Volatility over time")
# Calculate VaR and check for violations
Var <- -(exp(EWMA_mean[(2:numb_pred)]+sqrt(sigma2[(2:numb_pred)])*qnorm(0.95))-1)
Violations <- PortLoss[(back_obs):(numb_obs-2)] < Var
sum(Violations)
# HW 2 Q4  Part 1
# Produce 1 day VaR for hedged call option
library(RQuantLib)
# Option details
S <- 56.47   # Initial underlying price
delta <- 1/250 # time increment
maturity0 <- 0.376 # initial maturity
mu <- .1689
sigma <- .2066
n <- 10000 # Number of simulations
# Pre allocate space
AllLosses <- rep(0,n)
rand0_1 <- rnorm(n,0,1) # Pre generate numbers from normal(0,1) distribution
for (i in 1:n){
# Black Scholes Price and Greeks
Option <- EuropeanOption(type = "call", underlying = S, strike = 55, dividendYield = 0, riskFreeRate = 0.0084, maturity = 0.376, volatility = .2066)
# Position in stock (Option delta)
ht <- Option$delta
# Value of portfolio at time t
Vt <- S*ht - Option$value
# Stock Return is log normally distributed- use pre generated random number
X_t_delta <- delta* (mu-(sigma^2)/2)+ sigma* sqrt(delta)*rand0_1[i]
# New stock price- found using the stock return and previous return
S_t_delta <- exp(X_t_delta+log(S))
# New portfolio value
# New Option Price and Greeks - new stock price and maturity
New_Option <- EuropeanOption(type = "call", underlying = S_t_delta, strike = 55, dividendYield = 0, riskFreeRate = 0.0084, maturity = (0.376-delta), volatility = .2066)
# New portfolio value- same position (delta) but new option price and stock price
Vt_delta <- ht*S_t_delta - New_Option$value
# Loss operator is difference in portfolio values
L_t_delta <- Vt -Vt_delta
# Store losses
AllLosses[i] <- L_t_delta
}
#View the distribution of the losses
hist(AllLosses, breaks = 40)
abline(v = quantile(AllLosses, 0.95), col = "red")
# 95% VaR and 1day VaR * sqrt(10)
quantile(AllLosses, 0.95)
quantile(AllLosses, 0.95)*sqrt(10)
# HW 2 Q4
# Produce 10 day VaR for hedged call option
library(RQuantLib)
# Option details
S <- 56.47   # Initial underlying price
delta <- 1/250 # time increment
maturity0 <- 0.376 # initial maturity
mu <- .1689
sigma <- .2066
n <- 10000 # Number of simulations
nday <- 10
# Pre allocate space and generate random variables
AllLosses <- rep(0,n)
rand0_1 <- rnorm(nday*n,0,1) # Generate random samples
for (i in 1:n){ # For each simulaiton
Temp10DayLosses <- rep(0,nday)
for(j in 1:nday){ #For each day in the 10 day
# Black Scholes Price and Greeks
Option <- EuropeanOption(type = "call", underlying = S, strike = 55, dividendYield = 0, riskFreeRate = 0.0084, maturity = 0.376-j*(delta), volatility = .2066)
# Position in stock (Option delta)
ht <- Option$delta
# Value of portfolio at time t
Vt <- S*ht - Option$value
# Stock Return (Is the sigma2 divided by 2 or the mu - sigma2)
X_t_delta <- delta* (mu-(sigma^2)/2)+ sigma* sqrt(delta)*rand0_1[i*nday-j+1]
# New stock price- found using the stock return and previous return
S_t_delta <- exp(X_t_delta+log(S))
# New portfolio value
# New Option Price and Greeks - new stock price and maturity
New_Option <- EuropeanOption(type = "call", underlying = S_t_delta, strike = 55, dividendYield = 0, riskFreeRate = 0.0084, maturity = (0.376-(j+1)*delta), volatility = .2066)
# New portfolio value- same position (delta) but new option price and stock price
Vt_delta <- ht*S_t_delta - New_Option$value
# Loss operator is difference in portfolio values
L_t_delta <- Vt -Vt_delta
# Store temp losses
Temp10DayLosses[j] <- L_t_delta
# Reset stock price
S <- S_t_delta
} # End the 10 (nday) for loop
# Store Sum of 10 Day Losses
AllLosses[i] <- sum(Temp10DayLosses)
# Reset Stock price to initial price for new 10 day simulation
S <- 56.47
}
# 95% VaR
quantile(AllLosses, 0.95)
# Create histogram of the Losses with the 95% VaR
hist(AllLosses, breaks = 40)
abline(v = quantile(AllLosses, 0.95), col = "red")
quantile(AllLosses, 0.95)
# HW 2 Q4  Part 1
# Produce 1 day VaR for hedged call option
library(RQuantLib)
# Option details
S <- 56.47   # Initial underlying price
delta <- 1/250 # time increment
maturity0 <- 0.376 # initial maturity
mu <- .1689
sigma <- .2066
n <- 10000 # Number of simulations
# Pre allocate space
AllLosses <- rep(0,n)
rand0_1 <- rnorm(n,0,1) # Pre generate numbers from normal(0,1) distribution
for (i in 1:n){
# Black Scholes Price and Greeks
Option <- EuropeanOption(type = "call", underlying = S, strike = 55, dividendYield = 0, riskFreeRate = 0.0084, maturity = 0.376, volatility = .2066)
# Position in stock (Option delta)
ht <- Option$delta
# Value of portfolio at time t
Vt <- S*ht - Option$value
# Stock Return is log normally distributed- use pre generated random number
X_t_delta <- delta* (mu-(sigma^2)/2)+ sigma* sqrt(delta)*rand0_1[i]
# New stock price- found using the stock return and previous return
S_t_delta <- exp(X_t_delta+log(S))
# New portfolio value
# New Option Price and Greeks - new stock price and maturity
New_Option <- EuropeanOption(type = "call", underlying = S_t_delta, strike = 55, dividendYield = 0, riskFreeRate = 0.0084, maturity = (0.376-delta), volatility = .2066)
# New portfolio value- same position (delta) but new option price and stock price
Vt_delta <- ht*S_t_delta - New_Option$value
# Loss operator is difference in portfolio values
L_t_delta <- Vt -Vt_delta
# Store losses
AllLosses[i] <- L_t_delta
}
#View the distribution of the losses
hist(AllLosses, breaks = 40)
abline(v = quantile(AllLosses, 0.95), col = "red")
# 95% VaR and 1day VaR * sqrt(10)
quantile(AllLosses, 0.95)
quantile(AllLosses, 0.95)*sqrt(10)
# HW2Q5Pt1
# This file calculates the 95% VaR using a GARCH(1,1) method with EWMA means of the SP 500.
# We use a 4 year rolling window horizon to calibrate the parameters.
# We then back test the theoretical VaR against the next prediction of the next day to see if it falls outside the 95%
# We are looking the number of times the observed data exceeds the theoretical formulation.
# We expect the number of violations to be within the confidence interval in file ConfInt.R
# Let's get started....
# Set up the working directory and get the files needed
library(tseries)
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
# check the ordering of the date to make sure we are going forwards through time
back_obs <- 999  # Number of periods we go back to estimate the GARCH model
num_pred <- dim(SPData)[1]-back_obs
# Pre allocate space
coefs <- data.frame(matrix(0,nrow = num_pred, ncol = 3))
names(coefs)[1:3] <- c("a0", "a1", "b1")
for (i in 1:num_pred){ # Rolling window for the GARCH estimates
# Hypotetical Loss Operator - rolling window for 999 periods
PortLoss <- SPData[i:(i+back_obs),5]
# Fit Garch to portfolio losses (Trace = suppresses output to console, default is GARCH 1,1)
fit1 <- garch(PortLoss, trace = FALSE)
# Save coefficients of Garch models
coefs[i,1:3] <- fit1$coef
}
index <- seq(from = 1, to =dim(coefs)[1], by =1)
plot(index,coefs[,2])
# EWMA means
EWMA_mean <- rep(0,num_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:back_obs])
# Recursive definition for EWMA
for (i in 1:(num_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + SPData[(back_obs+i),5]*0.03
}
# Sigma 2 Initilization
sigma2 <- rep(0, num_pred)
sigma2[1] <- var(PortLoss[1:back_obs])
# Simga2 recursive definition using the coefficients from the rolling GARCH
for(i in 1:(num_pred-1)){
sigma2[(i+1)] <- coefs[i,1] + coefs[i,2]*(SPData[(back_obs+i),5]-EWMA_mean[i])^2+coefs[i,3]*sigma2[i]
}
# Take a look at the means and volatility over time
plot(EWMA_mean, main = "EWMA means over time")
plot(sigma2, main = " GARCH Volatility over time")
# Calculate the VaR for the rolling window
VaR <- EWMA_mean +sqrt(sigma2)*qnorm(0.95)
# Find how many time VaR was violated
violations <- sum(VaR>SPData[(back_obs+1):dim(SPData)[1],5]) # Some indexing probems are giving me NAs
num_pred - violations
# This is a little bit different from his possibly because we calculate the coefficients from garch differently
# HW2Q5Pt3
# This file computes the 95% VaR using variance/ covariance method with EWMA means and EMWA volatility
# We then back test the theoretical VaR against the next prediction of the next day to see if it falls outside the 95%
# We are looking the number of times the observed data exceeds the theoretical formulation.
# We expect the number of violations to be within the confidence interval in file ConfInt.R
# Let's get started
# Set up the working directory and get the files needed
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
# Some intial parameters
numb_obs <- dim(SPData)[1]
back_obs <- 999
numb_pred <- numb_obs- back_obs
Returns <- SPData$Log.Return
PortLoss <- SPData$Hypothetical.Portfolio.Loss
# EWMA means
EWMA_mean <- rep(0,numb_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:(back_obs)])
# Recursive definition for EWMA
for (i in 1:(numb_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + Returns[(back_obs+i)]*0.03
}
# Sigma2
# Pre allocate space and initialize first component
sigma2 <- rep(0, numb_pred)
sigma2[1] <- var(PortLoss[1:(1+back_obs)])
# Recursive equation for sigma
for(i in 1:(numb_pred-1)){
sigma2[i+1] <- 0.97*sigma2[i] + 0.03*(Returns[(i+back_obs)]-EWMA_mean[i])^2
}
# Take a peak at means and volatility
plot(EWMA_mean, main = "EWMA means over time")
plot(sigma2, main = "EWMA Volatility over time")
# Calculate VaR and check for violations
Var <- -(exp(EWMA_mean[(2:numb_pred)]+sqrt(sigma2[(2:numb_pred)])*qnorm(0.95))-1)
Violations <- PortLoss[(back_obs):(numb_obs-2)] < Var
sum(Violations)
# HW2Q5pt2
# Empirical VaR
# This file calculates the 95% VaR using the 95th quantile of the previous 1000 observations.
# We then see if the next period's loss is larger than this value
# We can compare this value to the range in ConfInt.R
# Let's get started
# Set things up
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
PortLoss <- SPData[[5]]
# Parameters for how many previous losses we use
numb_obs <- dim(SPData)[1]
back_obs <- 999
numb_pred <- numb_obs- back_obs
# Pre allocate space
Var <- rep(0,numb_pred)
Violation <- rep(0,numb_pred)
# Rolling window to find the quantile and check against observed data
for(i in 1:numb_pred){
Var[i] <- quantile(PortLoss[i:(back_obs+i)],0.95)
Violation[i] <- PortLoss[(i+back_obs)]>Var[i]
}
# Total number of violations
sum(Violation)
# Confidence Interval
m <- 1516
alpha <- 0.95
beta <- 0.05
N <- m*(1-alpha)
Z_1_b2 <- qnorm(0.975)
CI_upper <- N+Z_1_b2*sqrt(m*alpha*(1-alpha))
CI_lower <- N-Z_1_b2*sqrt(m*alpha*(1-alpha))
N
CI_upper
CI_lower
#
# x<- seq(from = 0, to = 140, by = 0.1)
# y <- dnorm(x, mean= N, sd = Z_1_b2*sqrt(m*alpha*(1-alpha)))
#
# plot(x,y, main"Confidence interval Estimates", type = "l")
# abline(v = c(79,46,50, CI_lower,CI_upper), col = c("blue", "green", "pink", "red", "red"))
# legend("topright",col = c("blue", "green", "pink", "red", "red"), c("EWMA", "Empirical", "Rolling Covariance", "Upper CI", "Lower CI"))
#
# EWMA Garch Violations
79
# Empirical violations
46
# Covariance
50
# EWMA is within confidence intervals but the other two are low estimators
# HW2Q5Pt3
# This file computes the 95% VaR using variance/ covariance method with EWMA means and EMWA volatility
# We then back test the theoretical VaR against the next prediction of the next day to see if it falls outside the 95%
# We are looking the number of times the observed data exceeds the theoretical formulation.
# We expect the number of violations to be within the confidence interval in file ConfInt.R
# Let's get started
# Set up the working directory and get the files needed
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
# Some intial parameters
numb_obs <- dim(SPData)[1]
back_obs <- 999
numb_pred <- numb_obs- back_obs
Returns <- SPData$Log.Return
PortLoss <- SPData$Hypothetical.Portfolio.Loss
# EWMA means
EWMA_mean <- rep(0,numb_pred)
# First value is the mean of the 1st 999 observations
EWMA_mean[1] <- mean(PortLoss[1:(back_obs)])
# Recursive definition for EWMA
for (i in 1:(numb_pred-1)){
EWMA_mean[i+1]<- EWMA_mean[i]*0.97 + Returns[(back_obs+i)]*0.03
}
# Sigma2
# Pre allocate space and initialize first component
sigma2 <- rep(0, numb_pred)
sigma2[1] <- var(PortLoss[1:(1+back_obs)])
# Recursive equation for sigma
for(i in 1:(numb_pred-1)){
sigma2[i+1] <- 0.97*sigma2[i] + 0.03*(Returns[(i+back_obs)]-EWMA_mean[i])^2
}
# Take a peak at means and volatility
plot(EWMA_mean, main = "EWMA means over time")
plot(sigma2, main = "EWMA Volatility over time")
# Calculate VaR and check for violations
Var <- -(exp(EWMA_mean[(2:numb_pred)]+sqrt(sigma2[(2:numb_pred)])*qnorm(0.95))-1)
Violations <- PortLoss[(back_obs):(numb_obs-2)] < Var
sum(Violations)
# HW2Q5pt2
# Empirical VaR
# This file calculates the 95% VaR using the 95th quantile of the previous 1000 observations.
# We then see if the next period's loss is larger than this value
# We can compare this value to the range in ConfInt.R
# Let's get started
# Set things up
setwd("C:/Users/board/Desktop/Kaggle/Value at Risk/Backtest SP500 VaR")
SPData <- read.csv("S_P_Daily_Log_Return_Data.csv")
head(SPData)
PortLoss <- SPData[[5]]
# Parameters for how many previous losses we use
numb_obs <- dim(SPData)[1]
back_obs <- 999
numb_pred <- numb_obs- back_obs
# Pre allocate space
Var <- rep(0,numb_pred)
Violation <- rep(0,numb_pred)
# Rolling window to find the quantile and check against observed data
for(i in 1:numb_pred){
Var[i] <- quantile(PortLoss[i:(back_obs+i)],0.95)
Violation[i] <- PortLoss[(i+back_obs)]>Var[i]
}
# Total number of violations
sum(Violation)
x<- seq(from = 0, to = 140, by = 0.1)
y <- dnorm(x, mean= N, sd = Z_1_b2*sqrt(m*alpha*(1-alpha)))
plot(x,y, main"Confidence interval Estimates", type = "l")
abline(v = c(79,46,50, CI_lower,CI_upper), col = c("blue", "green", "pink", "red", "red"))
legend("topright",col = c("blue", "green", "pink", "red", "red"), c("EWMA", "Empirical", "Rolling Covariance", "Upper CI", "Lower CI"))
plot(x,y, main"Confidence interval Estimates", type = "l")
plot(x,y, main = "Confidence interval Estimates", type = "l")
x<- seq(from = 20, to = 140, by = 0.1)
y <- dnorm(x, mean= N, sd = Z_1_b2*sqrt(m*alpha*(1-alpha)))
plot(x,y, main = "Confidence interval Estimates", type = "l")
abline(v = c(79,46,50, CI_lower,CI_upper), col = c("blue", "green", "pink", "red", "red"))
# Confidence Interval
m <- 1516
alpha <- 0.95
beta <- 0.05
N <- m*(1-alpha)
Z_1_b2 <- qnorm(0.975)
CI_upper <- N+Z_1_b2*sqrt(m*alpha*(1-alpha))
CI_lower <- N-Z_1_b2*sqrt(m*alpha*(1-alpha))
N
CI_upper
CI_lower
x<- seq(from = 20, to = 140, by = 0.1)
y <- dnorm(x, mean= N, sd = Z_1_b2*sqrt(m*alpha*(1-alpha)))
plot(x,y, main = "Confidence interval Estimates", type = "l")
abline(v = c(79,46,50, CI_lower,CI_upper), col = c("blue", "green", "pink", "red", "red"))
legend("topright",col = c("blue", "green", "pink", "red", "red"), c("EWMA", "Empirical", "Rolling Covariance", "Upper CI", "Lower CI"))
abline(v = c(79,46,50, CI_lower,CI_upper), col = c("blue", "green", "pink", "red", "red"), lwd = "3")
plot(x,y, main = "Confidence interval Estimates", type = "l", lwd = 2)
abline(v = c(79,46,50, CI_lower,CI_upper), col = c("blue", "green", "pink", "red", "red"), lwd = "3")
legend("topright",col = c("blue", "green", "pink", "red", "red"), c("EWMA", "Empirical", "Rolling Covariance", "Upper CI", "Lower CI"), lty = "1")
legend("topright",col = c("blue", "green", "pink", "red", "red"), c("EWMA", "Empirical", "Rolling Covariance", "Upper CI", "Lower CI"), lty = 1)
legend("topright",col = c("blue", "green", "pink", "red", "red"), c("EWMA", "Empirical", "Rolling Covariance", "Upper CI", "Lower CI"), lty = 1, lwd = 3)
